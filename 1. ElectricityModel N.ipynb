{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import time\n",
    "\n",
    "\n",
    "def custom_mre(y_true, y_pred):\n",
    "    \"\"\"numerator = tf.reduce_mean(tf.abs(y_pred - y_true), axis=None)\n",
    "    denominator = tf.reduce_mean(tf.abs(y_true), axis=None)\n",
    "    mre = 100.0 * numerator / denominator\n",
    "    return mre\"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    relative_error = np.abs((y_true - y_pred) / y_true)\n",
    "    \n",
    "    mre = np.mean(relative_error) * 100.0\n",
    "    \n",
    "    return mre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos desde el archivo CSV (asegúrate de ajustar el nombre del archivo)\n",
    "data = pd.read_csv('W168H24.csv')\n",
    "data_original = pd.read_csv('dataset.csv')\n",
    "\n",
    "# Eliminar la primera columna (índice 0)\n",
    "data = data.iloc[:, 1:]\n",
    "\n",
    "# Separar las características (entradas) y las etiquetas (salidas)\n",
    "X = data.iloc[:, :168].values  # Primeras 168 columnas son características de entrada\n",
    "y = data.iloc[:, 168:].values  # 24 columnas restantes son etiquetas de salida\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento (70%) y prueba (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación (70% - 30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=0)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_val = y_val.astype('float32')\n",
    "y_test = y_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                5070      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 80)                2480      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 90)                7290      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 60)                5460      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               6100      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 40)                4040      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 80)                3280      \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 80)                2480      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 50)                4050      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 40)                4040      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 80)                3280      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 90)                7290      \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 40)                3640      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 70)                2870      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 60)                4260      \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 90)                5490      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 70)                6370      \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 100)               7100      \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 24)                2424      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 118244 (461.89 KB)\n",
      "Trainable params: 118244 (461.89 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Definir el modelo de la red neuronal\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Agregar capa de entrada\n",
    "model.add(keras.layers.Input(shape=(168,)))  # Ahora son 168 características después de eliminar la primera columna\n",
    "\n",
    "# Agregar capas ocultas con las neuronas especificadas\n",
    "neuronas_ocultas = [30, 80, 90, 60, 60, 100, 40, 80, 30, 80, 50, 100, 40, 80, 90, 40, 70, 70, 70, 60, 90, 70, 100, 100]\n",
    "\n",
    "for neurons in neuronas_ocultas:\n",
    "    model.add(keras.layers.Dense(neurons, activation='tanh'))\n",
    "\n",
    "# Agregar capa de salida con 24 neuronas (salidas)\n",
    "model.add(keras.layers.Dense(24, activation='tanh'))\n",
    "\n",
    "# Definir el optimizador\n",
    "optimizer = keras.optimizers.Adam(epsilon=1E-8, learning_rate=0.0005)\n",
    "\n",
    "# Compilar el modelo con el optimizador personalizado\n",
    "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mean_squared_error','mean_absolute_error'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Configurar Early Stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Métrica a monitorear (en este caso, la pérdida en el conjunto de validación)\n",
    "    patience=10,  # Número de épocas sin mejora antes de detener el entrenamiento\n",
    "    min_delta=1E-4,  # Valor mínimo de mejora para considerar como una mejora significativa\n",
    "    restore_best_weights=True  # Restaurar los mejores pesos del modelo cuando se detiene\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "953/953 [==============================] - 8s 6ms/step - loss: 0.0410 - mean_squared_error: 0.0044 - val_loss: 0.0349 - val_mean_squared_error: 0.0023\n",
      "Epoch 2/300\n",
      "953/953 [==============================] - 5s 5ms/step - loss: 0.0270 - mean_squared_error: 0.0017 - val_loss: 0.0296 - val_mean_squared_error: 0.0018\n",
      "Epoch 3/300\n",
      "953/953 [==============================] - 5s 5ms/step - loss: 0.0240 - mean_squared_error: 0.0013 - val_loss: 0.0228 - val_mean_squared_error: 0.0011\n",
      "Epoch 4/300\n",
      "953/953 [==============================] - 5s 6ms/step - loss: 0.0226 - mean_squared_error: 0.0011 - val_loss: 0.0265 - val_mean_squared_error: 0.0013\n",
      "Epoch 5/300\n",
      "953/953 [==============================] - 5s 6ms/step - loss: 0.0205 - mean_squared_error: 8.5249e-04 - val_loss: 0.0231 - val_mean_squared_error: 9.5011e-04\n",
      "Epoch 6/300\n",
      "953/953 [==============================] - 5s 6ms/step - loss: 0.0195 - mean_squared_error: 7.6319e-04 - val_loss: 0.0176 - val_mean_squared_error: 6.5208e-04\n",
      "Epoch 7/300\n",
      "953/953 [==============================] - 5s 5ms/step - loss: 0.0188 - mean_squared_error: 7.0506e-04 - val_loss: 0.0173 - val_mean_squared_error: 6.0605e-04\n",
      "Epoch 8/300\n",
      "953/953 [==============================] - 5s 6ms/step - loss: 0.0176 - mean_squared_error: 6.1745e-04 - val_loss: 0.0163 - val_mean_squared_error: 5.2893e-04\n",
      "Epoch 9/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0174 - mean_squared_error: 5.8872e-04 - val_loss: 0.0188 - val_mean_squared_error: 6.5448e-04\n",
      "Epoch 10/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0169 - mean_squared_error: 5.5079e-04 - val_loss: 0.0171 - val_mean_squared_error: 5.3794e-04\n",
      "Epoch 11/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0165 - mean_squared_error: 5.2568e-04 - val_loss: 0.0149 - val_mean_squared_error: 4.6239e-04\n",
      "Epoch 12/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0163 - mean_squared_error: 5.1613e-04 - val_loss: 0.0187 - val_mean_squared_error: 6.1151e-04\n",
      "Epoch 13/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0156 - mean_squared_error: 4.7311e-04 - val_loss: 0.0143 - val_mean_squared_error: 4.0491e-04\n",
      "Epoch 14/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0155 - mean_squared_error: 4.6846e-04 - val_loss: 0.0172 - val_mean_squared_error: 5.3948e-04\n",
      "Epoch 15/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0153 - mean_squared_error: 4.5821e-04 - val_loss: 0.0157 - val_mean_squared_error: 4.6369e-04\n",
      "Epoch 16/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0151 - mean_squared_error: 4.4154e-04 - val_loss: 0.0144 - val_mean_squared_error: 4.0603e-04\n",
      "Epoch 17/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0148 - mean_squared_error: 4.2808e-04 - val_loss: 0.0150 - val_mean_squared_error: 5.0360e-04\n",
      "Epoch 18/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0148 - mean_squared_error: 4.2818e-04 - val_loss: 0.0161 - val_mean_squared_error: 4.8888e-04\n",
      "Epoch 19/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0144 - mean_squared_error: 4.0801e-04 - val_loss: 0.0140 - val_mean_squared_error: 3.8869e-04\n",
      "Epoch 20/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0142 - mean_squared_error: 3.9538e-04 - val_loss: 0.0171 - val_mean_squared_error: 5.2183e-04\n",
      "Epoch 21/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0146 - mean_squared_error: 4.1639e-04 - val_loss: 0.0136 - val_mean_squared_error: 3.7816e-04\n",
      "Epoch 22/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0141 - mean_squared_error: 3.9193e-04 - val_loss: 0.0145 - val_mean_squared_error: 3.9031e-04\n",
      "Epoch 23/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0141 - mean_squared_error: 3.8652e-04 - val_loss: 0.0131 - val_mean_squared_error: 3.4173e-04\n",
      "Epoch 24/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0141 - mean_squared_error: 3.8542e-04 - val_loss: 0.0129 - val_mean_squared_error: 3.3305e-04\n",
      "Epoch 25/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0138 - mean_squared_error: 3.7066e-04 - val_loss: 0.0158 - val_mean_squared_error: 5.3861e-04\n",
      "Epoch 26/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0137 - mean_squared_error: 3.6646e-04 - val_loss: 0.0178 - val_mean_squared_error: 5.4867e-04\n",
      "Epoch 27/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0137 - mean_squared_error: 3.6579e-04 - val_loss: 0.0128 - val_mean_squared_error: 3.2960e-04\n",
      "Epoch 28/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0136 - mean_squared_error: 3.5988e-04 - val_loss: 0.0149 - val_mean_squared_error: 4.1001e-04\n",
      "Epoch 29/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0137 - mean_squared_error: 3.6812e-04 - val_loss: 0.0132 - val_mean_squared_error: 3.4647e-04\n",
      "Epoch 30/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0135 - mean_squared_error: 3.5211e-04 - val_loss: 0.0128 - val_mean_squared_error: 3.3181e-04\n",
      "Epoch 31/300\n",
      "953/953 [==============================] - 6s 7ms/step - loss: 0.0133 - mean_squared_error: 3.4312e-04 - val_loss: 0.0124 - val_mean_squared_error: 3.0478e-04\n",
      "Epoch 32/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0134 - mean_squared_error: 3.4928e-04 - val_loss: 0.0124 - val_mean_squared_error: 3.1190e-04\n",
      "Epoch 33/300\n",
      "953/953 [==============================] - 6s 7ms/step - loss: 0.0132 - mean_squared_error: 3.4154e-04 - val_loss: 0.0132 - val_mean_squared_error: 3.2910e-04\n",
      "Epoch 34/300\n",
      "953/953 [==============================] - 7s 7ms/step - loss: 0.0130 - mean_squared_error: 3.3006e-04 - val_loss: 0.0126 - val_mean_squared_error: 3.1694e-04\n",
      "Epoch 35/300\n",
      "953/953 [==============================] - 6s 7ms/step - loss: 0.0132 - mean_squared_error: 3.3628e-04 - val_loss: 0.0123 - val_mean_squared_error: 2.9726e-04\n",
      "Epoch 36/300\n",
      "953/953 [==============================] - 6s 7ms/step - loss: 0.0131 - mean_squared_error: 3.3049e-04 - val_loss: 0.0126 - val_mean_squared_error: 3.0783e-04\n",
      "Epoch 37/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0130 - mean_squared_error: 3.2888e-04 - val_loss: 0.0128 - val_mean_squared_error: 3.1955e-04\n",
      "Epoch 38/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0128 - mean_squared_error: 3.2128e-04 - val_loss: 0.0132 - val_mean_squared_error: 3.9001e-04\n",
      "Epoch 39/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0129 - mean_squared_error: 3.2452e-04 - val_loss: 0.0120 - val_mean_squared_error: 2.8524e-04\n",
      "Epoch 40/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0128 - mean_squared_error: 3.1550e-04 - val_loss: 0.0160 - val_mean_squared_error: 4.3004e-04\n",
      "Epoch 41/300\n",
      "953/953 [==============================] - 6s 7ms/step - loss: 0.0127 - mean_squared_error: 3.1556e-04 - val_loss: 0.0121 - val_mean_squared_error: 2.9560e-04\n",
      "Epoch 42/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0127 - mean_squared_error: 3.1486e-04 - val_loss: 0.0130 - val_mean_squared_error: 3.1915e-04\n",
      "Epoch 43/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0127 - mean_squared_error: 3.1268e-04 - val_loss: 0.0125 - val_mean_squared_error: 3.1426e-04\n",
      "Epoch 44/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0128 - mean_squared_error: 3.1460e-04 - val_loss: 0.0116 - val_mean_squared_error: 2.7517e-04\n",
      "Epoch 45/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0124 - mean_squared_error: 3.0076e-04 - val_loss: 0.0120 - val_mean_squared_error: 2.7914e-04\n",
      "Epoch 46/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0125 - mean_squared_error: 3.0255e-04 - val_loss: 0.0127 - val_mean_squared_error: 3.0072e-04\n",
      "Epoch 47/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0128 - mean_squared_error: 3.1532e-04 - val_loss: 0.0124 - val_mean_squared_error: 2.8984e-04\n",
      "Epoch 48/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0124 - mean_squared_error: 2.9545e-04 - val_loss: 0.0121 - val_mean_squared_error: 2.9746e-04\n",
      "Epoch 49/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0125 - mean_squared_error: 3.0398e-04 - val_loss: 0.0126 - val_mean_squared_error: 3.2269e-04\n",
      "Epoch 50/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0123 - mean_squared_error: 2.9301e-04 - val_loss: 0.0134 - val_mean_squared_error: 4.2537e-04\n",
      "Epoch 51/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0125 - mean_squared_error: 3.0094e-04 - val_loss: 0.0122 - val_mean_squared_error: 2.8927e-04\n",
      "Epoch 52/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0123 - mean_squared_error: 2.9410e-04 - val_loss: 0.0140 - val_mean_squared_error: 3.5070e-04\n",
      "Epoch 53/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0123 - mean_squared_error: 2.9312e-04 - val_loss: 0.0120 - val_mean_squared_error: 2.7755e-04\n",
      "Epoch 54/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0121 - mean_squared_error: 2.8545e-04 - val_loss: 0.0126 - val_mean_squared_error: 3.4098e-04\n",
      "Epoch 55/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0122 - mean_squared_error: 2.9098e-04 - val_loss: 0.0120 - val_mean_squared_error: 2.8145e-04\n",
      "Epoch 56/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0123 - mean_squared_error: 2.9106e-04 - val_loss: 0.0117 - val_mean_squared_error: 2.6509e-04\n",
      "Epoch 57/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0121 - mean_squared_error: 2.8541e-04 - val_loss: 0.0131 - val_mean_squared_error: 3.0436e-04\n",
      "Epoch 58/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0120 - mean_squared_error: 2.8155e-04 - val_loss: 0.0118 - val_mean_squared_error: 2.6728e-04\n",
      "Epoch 59/300\n",
      "953/953 [==============================] - 6s 6ms/step - loss: 0.0121 - mean_squared_error: 2.8083e-04 - val_loss: 0.0122 - val_mean_squared_error: 2.8354e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AdrianGilGamboa\\Desktop\\PycharmProjects\\venv\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4667/4667 [==============================] - 5s 985us/step\n",
      "RMSE en el conjunto de prueba: 471.21063232421875\n",
      "MAE en el conjunto de prueba: 331.0008850097656\n",
      "MRE en el conjunto de prueba: 1.1600966565310955\n",
      "Mean absolute percentage error (MAPE):0.011601\n",
      "Tiempo de entrenamiento: 350.64 segundos\n",
      "Tiempo de entrenamiento (HH:MM:SS): 0:5:50\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con Early Stopping\n",
    "epochs = 300  \n",
    "batch_size = 256 \n",
    "# Comienza a medir el tiempo de entrenamiento\n",
    "start_time = time.time()\n",
    "#Entrenamiento del modelo\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "# Finaliza la medición del tiempo de entrenamiento\n",
    "end_time = time.time()\n",
    "\n",
    "#Guardar el modelo entrenado\n",
    "model_path = \"modelTrainedv3.h5\"\n",
    "model.save(model_path)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Desnormalización de los datos\n",
    "min_value = data_original['consumption'].min()\n",
    "max_value = data_original['consumption'].max()\n",
    "\n",
    "#Desnormalización de los valores\n",
    "y_pred_desnormalized = y_pred * (max_value - min_value) + min_value\n",
    "y_test_desnormalized = y_test * (max_value - min_value) + min_value\n",
    "\n",
    "# Calcular RMSE con datos desnormalizados\n",
    "rmse = np.sqrt(mean_squared_error(y_test_desnormalized, y_pred_desnormalized))\n",
    "print(f'RMSE en el conjunto de prueba: {rmse}')\n",
    "\n",
    "# Calcular MAE con datos desnormalizados\n",
    "mae = mean_absolute_error(y_test_desnormalized, y_pred_desnormalized)\n",
    "print(f'MAE en el conjunto de prueba: {mae}')\n",
    "\n",
    "# Calcular MRE con datos desnormalizados\n",
    "mre = custom_mre(y_test_desnormalized, y_pred_desnormalized)\n",
    "print(f'MRE en el conjunto de prueba: {mre}')\n",
    "\n",
    "#Calcular MAPE con datos desnormalizados\n",
    "print(\"Mean absolute percentage error (MAPE):%f\" % mean_absolute_percentage_error(y_test_desnormalized, y_pred_desnormalized))\n",
    "\n",
    "# Calcula la duración del entrenamiento en segundos\n",
    "training_duration = end_time - start_time\n",
    "# Imprime el tiempo de entrenamiento en segundos y en formato de horas, minutos y segundos\n",
    "print(f'Tiempo de entrenamiento: {training_duration:.2f} segundos')\n",
    "print(f'Tiempo de entrenamiento (HH:MM:SS): {int(training_duration // 3600)}:{int((training_duration % 3600) // 60)}:{int(training_duration % 60)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
